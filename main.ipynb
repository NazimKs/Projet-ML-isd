{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer,  WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\r\\n\\r\\nThis is a letter to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17302</th>\n",
       "      <td>ffd378d</td>\n",
       "      <td>the story \" The Challenge of Exploing Venus \" ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17303</th>\n",
       "      <td>ffddf1f</td>\n",
       "      <td>Technology has changed a lot of ways that we l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17304</th>\n",
       "      <td>fff016d</td>\n",
       "      <td>If you don't like sitting around all day than ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17305</th>\n",
       "      <td>fffb49b</td>\n",
       "      <td>In \"The Challenge of Exporing Venus,\" the auth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17306</th>\n",
       "      <td>fffed3e</td>\n",
       "      <td>Venus is worthy place to study but dangerous. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17307 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "0      000d118  Many people have car where they live. The thin...      3\n",
       "1      000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2      001ab80  People always wish they had the same technolog...      4\n",
       "3      001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4      002ba53  Dear, State Senator\\r\\n\\r\\nThis is a letter to...      3\n",
       "...        ...                                                ...    ...\n",
       "17302  ffd378d  the story \" The Challenge of Exploing Venus \" ...      2\n",
       "17303  ffddf1f  Technology has changed a lot of ways that we l...      4\n",
       "17304  fff016d  If you don't like sitting around all day than ...      2\n",
       "17305  fffb49b  In \"The Challenge of Exporing Venus,\" the auth...      1\n",
       "17306  fffed3e  Venus is worthy place to study but dangerous. ...      2\n",
       "\n",
       "[17307 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17307 entries, 0 to 17306\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   essay_id   17307 non-null  object\n",
      " 1   full_text  17307 non-null  object\n",
      " 2   score      17307 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 405.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.948402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.044899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "count  17307.000000\n",
       "mean       2.948402\n",
       "std        1.044899\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        4.000000\n",
       "max        6.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Many people have car where they live. The thin...\n",
       "1        I am a scientist at NASA that is discussing th...\n",
       "2        People always wish they had the same technolog...\n",
       "3        We all heard about Venus, the planet without a...\n",
       "4        Dear, State Senator\\r\\n\\r\\nThis is a letter to...\n",
       "                               ...                        \n",
       "17302    the story \" The Challenge of Exploing Venus \" ...\n",
       "17303    Technology has changed a lot of ways that we l...\n",
       "17304    If you don't like sitting around all day than ...\n",
       "17305    In \"The Challenge of Exporing Venus,\" the auth...\n",
       "17306    Venus is worthy place to study but dangerous. ...\n",
       "Name: full_text, Length: 17307, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[\"full_text\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        3\n",
       "2        4\n",
       "3        4\n",
       "4        3\n",
       "        ..\n",
       "17302    2\n",
       "17303    4\n",
       "17304    2\n",
       "17305    1\n",
       "17306    2\n",
       "Name: score, Length: 17307, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"score\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\keske\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\keske\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        mani peopl car live . thing n't know use car a...\n",
       "1        scientist nasa discuss `` face '' mar . explai...\n",
       "2        peopl alway wish technolog seen movi , best ne...\n",
       "3        heard venus , planet without almost oxygen ear...\n",
       "4        dear , state senat letter argu favor keep elec...\n",
       "                               ...                        \n",
       "17302    stori `` challeng explo venus `` inform piec d...\n",
       "17303    technolog chang lot way live today . nowaday p...\n",
       "17304    n't like sit around day great opportun partici...\n",
       "17305    `` challeng expor venus , '' author suggest st...\n",
       "17306    venus worthi place studi danger . reaosn thei ...\n",
       "Name: full_text, Length: 17307, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the PorterStemmer\n",
    "stemmer =  SnowballStemmer(\"english\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Apply stemming to each word\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    \n",
    "    # Join the stemmed words back into a sentence\n",
    "    stemmed_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return stemmed_text\n",
    "\n",
    "X = X.apply(preprocess_text)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 46602)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "#max_df=0.5, analyzer=\"word\", stop_words =\"english\"\n",
    "\n",
    "vectors = vectorizer.fit_transform(X).toarray()\n",
    "vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "vectors_modified = scaler.fit_transform(vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=100)\n",
    "\n",
    "X = pca.fit_transform(vectors_modified)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13845, 100)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.26275838, -1.4540641 , -0.2481939 , ..., -3.0171993 ,\n",
       "         0.80998943, -0.7540348 ],\n",
       "       [-0.05626606,  2.35154488, -0.90711338, ...,  0.32592391,\n",
       "         0.03017914,  0.20091424],\n",
       "       [-0.13880829,  1.54326858, -0.63813253, ...,  0.20711265,\n",
       "        -0.03209257,  0.0226431 ],\n",
       "       ...,\n",
       "       [-0.15895871,  0.25210053, -0.49447391, ...,  1.38782859,\n",
       "        -0.90865938,  0.92902688],\n",
       "       [-0.21864099,  4.37187256, -1.30210022, ...,  0.20895037,\n",
       "         1.08912361, -0.09404291],\n",
       "       [-0.17334852,  3.5747328 , -1.62608241, ...,  3.87512   ,\n",
       "        -1.56744886, -2.45816979]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3462, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12146545, -7.78172349,  0.76622798, ..., -0.59403661,\n",
       "         1.158326  , -0.19782985],\n",
       "       [-0.24405799,  5.39064074, -1.22346687, ..., -0.33680177,\n",
       "        -0.53255555, -0.02288904],\n",
       "       [-0.17723496,  3.10927293, -0.76172441, ..., -0.39357685,\n",
       "         0.11560728, -0.29153545],\n",
       "       ...,\n",
       "       [-0.14360153,  2.9709629 , -1.3384101 , ...,  0.78428386,\n",
       "        -0.0646788 ,  0.52663488],\n",
       "       [-0.04922457,  2.0444523 , -0.98764094, ...,  0.19353318,\n",
       "        -0.05074598, -0.21771477],\n",
       "       [-0.08412149,  2.72119331, -0.87431768, ...,  0.10429505,\n",
       "        -0.18251958, -0.18620802]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "Accuracy: 0.5569035239745812\n",
      "Precision: 0.5469551241789973\n",
      "Recall: 0.5569035239745812\n",
      "F1-score: 0.5424615150547746\n",
      "Confusion matrix:\n",
      "[[ 35 169  48   7   0   1]\n",
      " [ 24 642 270  27   0   2]\n",
      " [ 20 298 812 131   3   1]\n",
      " [  2  16 313 379  34   6]\n",
      " [  1   0   7 117  49   9]\n",
      " [  0   0   0   6  22  11]]\n",
      "r2_score = 0.45492485736920485\n",
      "mse = 0.6013864818024264\n",
      "Support Vector Machine \n",
      "Accuracy: 0.5618139803581744\n",
      "Precision: 0.5433440505979913\n",
      "Recall: 0.5618139803581744\n",
      "F1-score: 0.5414281736535433\n",
      "Confusion matrix:\n",
      "[[ 13 193  43  10   0   1]\n",
      " [ 15 668 251  29   2   0]\n",
      " [ 14 309 787 153   2   0]\n",
      " [  1  16 288 416  25   4]\n",
      " [  0   1   6 119  48   9]\n",
      " [  0   0   0   7  19  13]]\n",
      "r2_score = 0.4722038964727747\n",
      "mse = 0.5823223570190641\n",
      "Random Forest Classifier \n",
      "Accuracy: 0.5814558058925476\n",
      "Precision: 0.5807055025215634\n",
      "Recall: 0.5814558058925476\n",
      "F1-score: 0.5672865774048815\n",
      "Confusion matrix:\n",
      "[[ 31 155  69   5   0   0]\n",
      " [ 14 590 329  30   2   0]\n",
      " [  8 210 856 189   2   0]\n",
      " [  1   8 241 454  43   3]\n",
      " [  0   1   3 103  71   5]\n",
      " [  0   0   0   2  26  11]]\n",
      "r2_score = 0.5036203312065382\n",
      "mse = 0.5476603119584056\n",
      "Gradient Boosting Classifier \n",
      "Accuracy: 0.5805892547660312\n",
      "Precision: 0.5752868843122783\n",
      "Recall: 0.5805892547660312\n",
      "F1-score: 0.5724651291183763\n",
      "Confusion matrix:\n",
      "[[ 53 149  48  10   0   0]\n",
      " [ 34 587 310  30   2   2]\n",
      " [ 22 204 835 200   4   0]\n",
      " [  5   5 241 449  48   2]\n",
      " [  0   0   3 103  72   5]\n",
      " [  0   0   0   2  23  14]]\n",
      "r2_score = 0.48529407761184284\n",
      "mse = 0.5678798382437897\n",
      "Neural Network \n",
      "Accuracy: 0.5459272097053726\n",
      "Precision: 0.5431921760900581\n",
      "Recall: 0.5459272097053726\n",
      "F1-score: 0.5430585442700432\n",
      "Confusion matrix:\n",
      "[[ 85 129  38   8   0   0]\n",
      " [ 74 587 261  43   0   0]\n",
      " [ 35 249 714 262   4   1]\n",
      " [ 12  27 215 432  56   8]\n",
      " [  1   2   8 102  55  15]\n",
      " [  0   0   0   8  14  17]]\n",
      "r2_score = 0.4020405255673698\n",
      "mse = 0.659734257654535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# import xgboost as xgb\n",
    "# from xgb import XGBClassifier\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    # 'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Support Vector Machine': SVC(kernel='linear'),\n",
    "    'Random Forest Classifier': RandomForestClassifier(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    # 'XGBoost Classifier' : XGBClassifier(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"{name} \")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"F1-score:\", f1)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3462 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_true  y_pred\n",
       "0          4       3\n",
       "1          4       3\n",
       "2          2       3\n",
       "3          2       3\n",
       "4          4       4\n",
       "...      ...     ...\n",
       "3457       2       1\n",
       "3458       1       2\n",
       "3459       2       2\n",
       "3460       2       2\n",
       "3461       2       2\n",
       "\n",
       "[3462 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'y_true': y_pred, 'y_pred': y_test.to_numpy()})\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    # 'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Support Vector Machine': SVC(kernel='linear'),\n",
    "    'Random Forest Classifier': RandomForestClassifier(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    # 'XGBoost Classifier' : XGBClassifier(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    accuracy_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "    precision_scores = cross_val_score(model, X, y, cv=kf, scoring='precision_weighted')\n",
    "    recall_scores = cross_val_score(model, X, y, cv=kf, scoring='recall_weighted')\n",
    "    f1_scores = cross_val_score(model, X, y, cv=kf, scoring='f1_weighted')\n",
    "\n",
    "    # Print average scores\n",
    "    print(\"Average Accuracy:\", np.mean(accuracy_scores))\n",
    "    print(\"Average Precision:\", np.mean(precision_scores))\n",
    "    print(\"Average Recall:\", np.mean(recall_scores))\n",
    "    print(\"Average F1-score:\", np.mean(f1_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
